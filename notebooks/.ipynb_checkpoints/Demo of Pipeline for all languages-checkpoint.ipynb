{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the `NLP()` pipeline on all available languages.\n",
    "\n",
    "If dependency parse information is available, an example tree is printed, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk import NLP\n",
    "from cltk.dependency.tree import DependencyTree\n",
    "from cltk.languages.example_texts import get_example_text\n",
    "from cltk.languages.pipelines import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_to_pipeline = {\n",
    "    \"akk\": AkkadianPipeline,\n",
    "    \"ang\": OldEnglishPipeline,\n",
    "    \"arb\": ArabicPipeline,\n",
    "    \"arc\": AramaicPipeline,\n",
    "    \"chu\": OCSPipeline,\n",
    "    \"cop\": CopticPipeline,\n",
    "    \"enm\": MiddleEnglishPipeline,\n",
    "    \"frm\": MiddleFrenchPipeline,\n",
    "    \"fro\": OldFrenchPipeline,\n",
    "    \"gmh\": MiddleHighGermanPipeline,\n",
    "    \"got\": GothicPipeline,\n",
    "    \"grc\": GreekPipeline,\n",
    "    \"hin\": HindiPipeline,\n",
    "    \"lat\": LatinPipeline,\n",
    "    \"lzh\": ChinesePipeline,\n",
    "    \"non\": OldNorsePipeline,\n",
    "    \"pan\": PanjabiPipeline,\n",
    "    \"pli\": PaliPipeline,\n",
    "    \"san\": SanskritPipeline,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akkadian ('akk') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Akkadian' (ISO: 'akk'): `AkkadianTokenizationProcess`, `StopsProcess`.\n",
      "Example `Word`: Word(index_char_start=0, index_char_stop=2, index_token=0, index_sentence=None, string=('u2-wa-a-ru', 'akkadian'), pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Old English (ca. 450-1100) ('ang') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Old English (ca. 450-1100)' (ISO: 'ang'): `MultilingualTokenizationProcess`, `OldEnglishLemmatizationProcess`, `OldEnglishEmbeddingsProcess`, `StopsProcess`.\n",
      "This part of the CLTK depends upon models from the CLTK project.\n",
      "Do you want to download 'https://github.com/cltk/ang_models_cltk' to '~/cltk_data/ang'? [Y/n] \n",
      "Y\n",
      "Example `Word`: Word(index_char_start=0, index_char_stop=5, index_token=0, index_sentence=None, string='Hw√¶t.', pos=None, lemma='Hw√¶t.', stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Standard Arabic ('arb') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Standard Arabic' (ISO: 'arb'): `ArabicTokenizationProcess`, `ArabicEmbeddingsProcess`, `StopsProcess`.\n",
      "CLTK message: This part of the CLTK depends upon word embedding models from the Fasttext project.\n",
      "Do you want to download file 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ar.vec' to '/Users/kylejohnson/cltk_data/arb/embeddings/fasttext/wiki.ar.vec'? [Y/n] \n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.61G/1.61G [01:32<00:00, 17.4MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `Word`: Word(index_char_start=0, index_char_stop=5, index_token=0, index_sentence=None, string='ŸÉŸáŸäÿπÿµ', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Official Aramaic (700-300 BCE) ('arc') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Official Aramaic (700-300 BCE)' (ISO: 'arc'): `ArabicTokenizationProcess`, `AramaicEmbeddingsProcess`.\n",
      "CLTK message: This part of the CLTK depends upon word embedding models from the Fasttext project.\n",
      "Do you want to download file 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.arc.vec' to '/Users/kylejohnson/cltk_data/arc/embeddings/fasttext/wiki.arc.vec'? [Y/n] \n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.66M/8.66M [00:00<00:00, 8.69MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `Word`: Word(index_char_start=0, index_char_stop=1, index_token=0, index_sentence=None, string='‹í', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=None, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Church Slavic ('chu') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Church Slavic' (ISO: 'chu'): `OCSStanzaProcess`.\n",
      "Unrecognized UD `feature_name` ('Variant') with `feature_value` ('Short').\n",
      "Please raise an issue at <https://github.com/cltk/cltk/issues> and include a small sample to reproduce the error.\n",
      "Unrecognized UD `feature_name` ('Variant') with `feature_value` ('Short').\n",
      "Please raise an issue at <https://github.com/cltk/cltk/issues> and include a small sample to reproduce the error.\n",
      "Example `Word`: Word(index_char_start=None, index_char_stop=None, index_token=0, index_sentence=0, string='–æ—Ç—å—á—î', pos=noun, lemma='–æ—Ç—å—á—å', stem=None, scansion=None, xpos='Nb', upos='NOUN', dependency_relation='nsubj', governor=7, features={Case: [nominative], Gender: [masculine], Number: [singular]}, category={F: [neg], N: [pos], V: [neg]}, stop=None, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Coptic ('cop') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Coptic' (ISO: 'cop'): `CopticStanzaProcess`, `StopsProcess`.\n",
      "Example `Word`: Word(index_char_start=None, index_char_stop=None, index_token=0, index_sentence=0, string='‚≤ß', pos=determiner, lemma='‚≤°', stem=None, scansion=None, xpos='ART', upos='DET', dependency_relation='det', governor=1, features={Definiteness: [definite], Gender: [feminine], Number: [singular], PrononimalType: [article]}, category={F: [pos], N: [pos], V: [neg]}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Middle English ('enm') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Middle English' (ISO: 'enm'): `MiddleEnglishTokenizationProcess`, `StopsProcess`, `MiddleEnglishEmbeddingsProcess`.\n",
      "CLTK message: This part of the CLTK depends upon word embedding models from the NLPL project.\n",
      "Do you want to download the enm models to /Users/kylejohnson/cltk_data/enm/model/enm_models_cltk/semantics'? [Y/n] \n",
      "Y\n",
      "Example `Word`: Word(index_char_start=0, index_char_stop=6, index_token=0, index_sentence=None, string='Whilom', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Middle French ('frm') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Middle French' (ISO: 'frm'): `MiddleFrenchTokenizationProcess`.\n",
      "Example `Word`: Word(index_char_start=0, index_char_stop=8, index_token=0, index_sentence=None, string='Attilius', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=None, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Old French (842-ca. 1400) ('fro') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Old French (842-ca. 1400)' (ISO: 'fro'): `OldFrenchStanzaProcess`, `StopsProcess`, `OldFrenchNERProcess`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Old French model path '/Users/kylejohnson/cltk_data/fro/model/fro_models_cltk/named_entities_fr.py' not found. Going to try to download it ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This part of the CLTK depends upon models from the CLTK project.\n",
      "Do you want to download 'https://github.com/cltk/fro_models_cltk' to '~/cltk_data/fro'? [Y/n] \n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:CLTK:Cloning 'fro_models_cltk' from 'https://github.com/cltk/fro_models_cltk.git'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `Word`: Word(index_char_start=None, index_char_stop=None, index_token=0, index_sentence=0, string='Une', pos=determiner, lemma='Une', stem=None, scansion=None, xpos='DETndf', upos='DET', dependency_relation='det', governor=1, features={Definiteness: [indefinite], PrononimalType: [article]}, category={F: [pos], N: [pos], V: [neg]}, stop=False, named_entity=False, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Middle High German ('gmh') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Middle High German' (ISO: 'gmh'): `MiddleHighGermanTokenizationProcess`, `StopsProcess`.\n",
      "Example `Word`: Word(index_char_start=0, index_char_stop=3, index_token=0, index_sentence=None, string='Uns', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Gothic ('got') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Gothic' (ISO: 'got'): `GothicStanzaProcess`, `GothicEmbeddingsProcess`.\n",
      "CLTK message: This part of the CLTK depends upon word embedding models from the Fasttext project.\n",
      "Do you want to download file 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.got.vec' to '/Users/kylejohnson/cltk_data/got/embeddings/fasttext/wiki.got.vec'? [Y/n] \n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.94M/6.94M [00:01<00:00, 6.21MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `Word`: Word(index_char_start=None, index_char_stop=None, index_token=0, index_sentence=0, string='swa', pos=adverb, lemma='swa', stem=None, scansion=None, xpos='Df', upos='ADV', dependency_relation='advmod', governor=1, features={}, category={F: [neg], N: [pos], V: [pos]}, stop=None, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Ancient Greek ('grc') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekStanzaProcess`, `GreekEmbeddingsProcess`, `StopsProcess`.\n",
      "Example `Word`: Word(index_char_start=None, index_char_stop=None, index_token=0, index_sentence=0, string='·ΩÖœÑŒπ', pos=adverb, lemma='·ΩÖœÑŒπ', stem=None, scansion=None, xpos='Df', upos='ADV', dependency_relation='advmod', governor=6, features={}, category={F: [neg], N: [pos], V: [pos]}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Hindi ('hin') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Hindi' (ISO: 'hin'): `MultilingualTokenizationProcess`, `StopsProcess`.\n",
      "Example `Word`: Word(index_char_start=0, index_char_stop=3, index_token=0, index_sentence=None, string='‡§Æ‡•à‡§Ç', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Latin ('lat') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Latin' (ISO: 'lat'): `LatinNormalizeProcess`, `LatinStanzaProcess`, `LatinEmbeddingsProcess`, `StopsProcess`, `LatinLexiconProcess`.\n",
      "Example `Word`: Word(index_char_start=None, index_char_stop=None, index_token=0, index_sentence=0, string='Gallia', pos=noun, lemma='Gallia', stem=None, scansion=None, xpos='A1|grn1|casA|gen2', upos='NOUN', dependency_relation='nsubj', governor=1, features={Case: [nominative], Gender: [feminine], Number: [singular]}, category={F: [neg], N: [pos], V: [neg]}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition='')\n",
      "\n",
      "Literary Chinese ('lzh') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Literary Chinese' (ISO: 'lzh'): `ChineseStanzaProcess`.\n",
      "Example `Word`: Word(index_char_start=None, index_char_stop=None, index_token=0, index_sentence=0, string='ÈªÉ', pos=proper_noun, lemma='ÈªÉ', stem=None, scansion=None, xpos='n,ÂêçË©û,‰∫∫,Âêç', upos='PROPN', dependency_relation='compound', governor=1, features={NameType: [person_given_name]}, category={F: [neg], N: [pos], V: [neg]}, stop=None, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Old Norse ('non') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Old Norse' (ISO: 'non'): `OldNorseTokenizationProcess`, `StopsProcess`, `OldNorseLexiconProcess`.\n",
      "This part of the CLTK depends upon Zo√´ga's *A Concise Old Norse Dictionary* (1890).\n",
      "Do you want to download this? [Y/n] \n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:CLTK:Cloning 'cltk_non_zoega_dictionary' from 'https://github.com/cltk/cltk_non_zoega_dictionary.git'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `Word`: Word(index_char_start=0, index_char_stop=5, index_token=0, index_sentence=None, string='Gylfi', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition='')\n",
      "\n",
      "Eastern Panjabi ('pan') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Eastern Panjabi' (ISO: 'pan'): `MultilingualTokenizationProcess`, `StopsProcess`.\n",
      "Example `Word`: Word(index_char_start=0, index_char_stop=3, index_token=0, index_sentence=None, string='‡®Ü‡®ø‡®¶', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Pali ('pli') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Pali' (ISO: 'pli'): `MultilingualTokenizationProcess`, `PaliEmbeddingsProcess`.\n",
      "CLTK message: This part of the CLTK depends upon word embedding models from the Fasttext project.\n",
      "Do you want to download file 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.pi.vec' to '/Users/kylejohnson/cltk_data/pli/embeddings/fasttext/wiki.pi.vec'? [Y/n] \n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.02M/5.02M [00:00<00:00, 5.63MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `Word`: Word(index_char_start=0, index_char_stop=6, index_token=0, index_sentence=None, string='Raajaa', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=None, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n",
      "Sanskrit ('san') ...\n",
      "‚Äéê§Ä CLTK version '1.1.5'.\n",
      "Pipeline for language 'Sanskrit' (ISO: 'san'): `MultilingualTokenizationProcess`, `SanskritEmbeddingsProcess`, `StopsProcess`.\n",
      "CLTK message: This part of the CLTK depends upon word embedding models from the Fasttext project.\n",
      "Do you want to download file 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.sa.vec' to '/Users/kylejohnson/cltk_data/san/embeddings/fasttext/wiki.sa.vec'? [Y/n] \n",
      "Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129M/129M [00:08<00:00, 15.3MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example `Word`: Word(index_char_start=0, index_char_stop=3, index_token=0, index_sentence=None, string='‡§à‡§∂‡§æ', pos=None, lemma=None, stem=None, scansion=None, xpos=None, upos=None, dependency_relation=None, governor=None, features={}, category={}, stop=False, named_entity=None, syllables=None, phonetic_transcription=None, definition=None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lang, pipeline in iso_to_pipeline.items():\n",
    "    print(f\"{pipeline.language.name} ('{pipeline.language.iso_639_3_code}') ...\")\n",
    "    text = get_example_text(lang)\n",
    "    cltk_nlp = NLP(language=lang)\n",
    "    cltk_doc = cltk_nlp.analyze(text=text)\n",
    "    cltk_doc.sentences_strings\n",
    "    word = cltk_doc.sentences[0][0]\n",
    "    print(\"Example `Word`:\", word)\n",
    "    if all([w.features for w in cltk_doc.sentences[0]]):\n",
    "        print(\"Printing dependency tree of first sentence ...\")\n",
    "        try:\n",
    "            a_tree = DependencyTree.to_tree(cltk_doc.sentences[0])\n",
    "        except:\n",
    "            print(f\"Dependency parsing Process not available for '{lang}'.\")\n",
    "            print(\"\")\n",
    "            continue\n",
    "        a_tree.print_tree()\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
